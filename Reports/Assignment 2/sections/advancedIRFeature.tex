%!TEX root = ../report.tex

\section{Advanced IR Feature}
\label{sec:advancedIRFeature}
As our advanced information retrieval feature we selected automatic query expansion, also known as pseudo-relevance feedback. Queries might be hard to specify for users and there is a danger that the user searches for a synonym to a word that is more significant in the document collection\,\cite{billerbeckzobel04}. The idea is to expand the initial query with $E$ additional terms that are statistically related to the query to mitigate this vocabulary mismatch\,\cite{billerbeckzobel04}. The steps to automatic query expansion are\,\cite{scholer13}: 

\begin{enumerate}
	\item Perform ranked retrieval on the initial query with a good similarity measure and assume that the top $R$ ranked documents are relevant.
	\item Parse through these $R$ documents and mark all terms in these candidate terms for query expansion.
	\item Select the best $E$ of these candidate terms for the query expansion by evaluating them with some statistical method.
	\item Append the $E$ terms to the initial query and run the ranked retrieval procedure again. This is the final result.
\end{enumerate}

As the statistical method in step three, we use the Okapi Term Selection Value (TSV) approach to select a set of $E$ terms to extend the initial query with\,\cite{billerbeckzobel04}\cite{Robertson_okapi/keenbowat}.

\subsection*{Implementation}
We have extended the BM25RankedQueryEngine presented in Section \ref{sec:rankedRetrieval} to handle the query expansion. The class is called QueryExpansionBM25QueryEngine and is automatically used as query engine if the $-QEBM25$ input flag is specified. The getResults method of the class follows the approach described above with the most difficult step being step 2, as the current invertedIndex does not allow us to retrieve all terms for a particular document. For step 1 of the algorithm we simply call the getResults method of the BM25RankedQueryEngine.

To get part 2 working we have had to do some extra work at indexing time. We save an uninverted index of documents, where document IDs in the term lexicon (termLex) point to a term list in the termIndex. We also save a term map that maps a term ID to a specific term, called termMap. Keeping track of this extra termMap allows us to reuse our indexing and compression code from assignment one, as we are once again only saving numerical data in the termIndex file\,\cite{dahlsmith13}. 

So when the list of candidate terms is requested, each document's term list is found by first looking up the byte offset (into the termIndex) of the list of terms, which is listed in the termLex (lexicon). The findCandidateTerms method performs this procedure for each of the $R$ documents and uses a HashMap\,\cite{hashmap} from term IDs to frequencies, to make sure that terms occurring in multiple documents are only saved as candidate terms once. The frequencies mentioned are not the within-document frequencies but the ``number of documents in the initially retrieved pool that contain the term''\,\cite{scholer13}, as this measure is later to be used in the TSV calculation.

When the candidate terms have been retrieved, the next job is to compute the TSV scores and provide the $E$ lowest results. We again apply a Minheap in the form of a Java PriorityQueue\,\cite{priorityqueue} to efficiently sort and retrieve the lowest-valued candidate terms.

Lastly, the initial query is expanded with the $E$ lowest-valued candidate terms, the getResults method of BM25RankedQueryEngine is run again with this new query, and the results of this process are returned as the final results of the ranked retrieval procedure.
