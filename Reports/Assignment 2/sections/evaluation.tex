%!TEX root = ../report.tex
\setlength{\tabcolsep}{15pt}
\section{Evaluation}
\label{sec:evaluation}
\subsection*{P@10 Evaluation}

The \textit{Precision at 10} metric describes the precision of a query after 10 answers have been seen. The P@10 score is equal to the number of relevant results divided by the number of answers, or $\frac{R}{10}$. This metric is often used since it reflects the relevance of the first page of search results returned by a web search engine, given the general default display of 10 answers per page. Since, as studies have shown, most users do not look past the first page of search results, this is a good general reflection of the relevance of the query result\,\cite{scholer13_6}.

\paragraph*{}

The provided queries were run using the BM25 and BM25 with query expansion (hereafter referred to as \textit{BM25QE}) querying methods. This can be seen in Appendix \ref{query_results}. The BM25QE function can be run with varying values for $R$ (the number of top-ranked documents that are assumed to be relevant)and $E$ (the number of terms that should be appended to the original query). We first ran the given queries with several different values of $R$ and $E$ to choose optimal values for comparison.

The average relevance score using the P@10 metric (discussed in the next section) over the five queries with each combination of $R$ and $E$ values is shown in Table \ref{table:BM25QEtest}.

\begin{centering}
\begin{table}
\makebox[\textwidth]{
	\begin{tabular}{ c | c c c c c c }
		        &$E=5$ &$E=10$&$E=15$&$E=20$&$E=25$&$E=30$\\
		\hline
		$R=5$   & 0.22 & 0.26 & 0.20 & 0.22 & 0.18 & 0.22\\
		$R=10$  & 0.28 & 0.32 & 0.26 & 0.28 & 0.30 & 0.30\\
		$R=15$  & 0.26 & 0.24 & 0.24 & 0.22 & 0.22 & 0.24\\
		$R=20$  & 0.24 & 0.26 & 0.20 & 0.20 & 0.20 & 0.20\\
		$R=25$  & 0.26 & 0.24 & 0.18 & 0.18 & 0.16 & 0.16\\
		$R=30$  & 0.20 & 0.22 & 0.20 & 0.16 & 0.16 & 0.16\\
	\end{tabular}
}
\caption {Average P@10 score for BM25QE with different combinations of R and E}\label{table:BM25QEtest}
\end{table}
\end{centering}

We can see that the P@10 relevance score is maximised when $R=10$, but there is not as definite a forerunner when setting $E$. As a result we chose to use several different values of $E$ in the comparison between BM25QE and BM25.

\begin{centering}
\begin{table}
\makebox[\textwidth]{
	\begin{tabular}{ c | c c c c }
		Query & BM25 & BM25QE $E=10$&BM25QE $E=25$&BM25QE $E=30$\\
		\hline
		401 & 0.1  & 0.0  & 0.0  & 0.0 \\
		402 & 0.2  & 0.1  & 0.2  & 0.2 \\
		403 & 0.6  & 0.7  & 0.6  & 0.6 \\
		405 & 0.2  & 0.5  & 0.4  & 0.4 \\
		408 & 0.4  & 0.3  & 0.3  & 0.3 \\
		\hline
		Avg & 0.30 & 0.32 & 0.30 & 0.30 \\
	\end{tabular}
}
\caption {P@10 relevance score for each query method}\label{table:Pat10result}
\end{table}
\end{centering}

Table \ref{table:Pat10result} lists the number of relevant documents listed in the top 10 ranked query results for each querying method.

\newpage
\subsection*{P@R Evaluation}